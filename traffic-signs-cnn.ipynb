{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/traffic-signs-preprocessed/data8.pickle\n/kaggle/input/traffic-signs-preprocessed/data4.pickle\n/kaggle/input/traffic-signs-preprocessed/test.pickle\n/kaggle/input/traffic-signs-preprocessed/std_rgb.pickle\n/kaggle/input/traffic-signs-preprocessed/data5.pickle\n/kaggle/input/traffic-signs-preprocessed/data3.pickle\n/kaggle/input/traffic-signs-preprocessed/mean_image_gray.pickle\n/kaggle/input/traffic-signs-preprocessed/labels.pickle\n/kaggle/input/traffic-signs-preprocessed/data1.pickle\n/kaggle/input/traffic-signs-preprocessed/mean_image_rgb.pickle\n/kaggle/input/traffic-signs-preprocessed/valid.pickle\n/kaggle/input/traffic-signs-preprocessed/data0.pickle\n/kaggle/input/traffic-signs-preprocessed/std_gray.pickle\n/kaggle/input/traffic-signs-preprocessed/data6.pickle\n/kaggle/input/traffic-signs-preprocessed/label_names.csv\n/kaggle/input/traffic-signs-preprocessed/datasets_preparing.py\n/kaggle/input/traffic-signs-preprocessed/data7.pickle\n/kaggle/input/traffic-signs-preprocessed/train.pickle\n/kaggle/input/traffic-signs-preprocessed/data2.pickle\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_pickle('/kaggle/input/traffic-signs-preprocessed/data8.pickle')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"{'y_validation': array([ 9, 37, 31, ...,  5, 18,  6], dtype=uint8),\n 'x_train': array([[[[-0.54642206,  1.0425833 ,  0.79494214, ..., -0.70286393,\n           -0.67279685, -0.602346  ],\n          [-0.6146229 ,  0.74160224,  0.5867728 , ...,  0.16095497,\n            0.15466528,  0.0214771 ],\n          [-0.69638306,  0.5387884 ,  0.44214383, ..., -0.06861585,\n           -0.24066828, -0.35183737],\n          ...,\n          [ 0.12834986,  0.41358492,  0.5119226 , ...,  0.3618001 ,\n            0.545381  , -0.48002478],\n          [ 0.4186098 ,  0.38220668,  0.47971445, ...,  0.55423665,\n            0.73357224, -0.4668069 ],\n          [-0.54892397, -0.61771524, -0.6314567 , ...,  0.68108726,\n            0.85835606, -0.4669531 ]]],\n \n \n        [[[-0.54642206, -0.56189924, -0.6495985 , ..., -0.12373468,\n            0.02414251, -0.54330283],\n          [-0.03432735,  0.15697211,  0.10856288, ..., -0.5076013 ,\n           -0.14035697, -0.6238451 ],\n          [-0.17071831, -0.12555376, -0.0688336 , ..., -0.70964766,\n           -0.36201033, -0.70586354],\n          ...,\n          [-0.3411084 ,  0.48219812, -0.49000028, ...,  1.1981417 ,\n            1.7745035 ,  1.077938  ],\n          [-0.06001614,  1.3204398 ,  0.6182278 , ...,  1.4360467 ,\n            1.9566792 ,  1.1978731 ],\n          [ 0.16084434,  1.8574777 ,  1.332871  , ...,  0.2707949 ,\n            0.71847534, -0.17940794]]],\n \n \n        [[[-0.25243405, -0.3884417 , -0.53403515, ...,  0.45539445,\n           -0.2662489 , -0.48425975],\n          [-0.32447508, -0.48612106, -0.7283045 , ...,  0.22173281,\n           -0.43537927, -0.56517947],\n          [-0.46275425, -0.7295012 , -0.96304417, ..., -0.00451267,\n           -0.6046943 , -0.70586354],\n          ...,\n          [ 3.2636602 ,  3.003734  ,  1.9253495 , ...,  0.7888682 ,\n            0.8223663 ,  0.60377544],\n          [ 3.3416467 ,  3.1627882 ,  1.9860473 , ...,  0.90004444,\n            1.4054198 ,  0.7123414 ],\n          [ 3.3370574 ,  3.380673  ,  2.0844395 , ...,  1.1597619 ,\n            1.7500956 ,  1.1145452 ]]],\n \n \n        ...,\n \n \n        [[[-0.6640173 ,  0.6523037 ,  1.1271864 , ..., -0.81868976,\n           -0.73087513, -0.66138905],\n          [-0.73068196,  0.74160224,  1.2891437 , ...,  0.22173281,\n            0.21366973,  0.25613967],\n          [-0.81319743,  1.2484267 ,  2.0229805 , ...,  0.7486998 ,\n            0.7149    ,  0.65123665],\n          ...,\n          [ 2.9953983 ,  2.8665075 ,  2.7841406 , ...,  0.9134297 ,\n            1.0127939 , -0.6832374 ],\n          [ 2.7946455 ,  3.0263178 ,  2.8863842 , ...,  0.8308829 ,\n            0.94029456, -0.67489195],\n          [-0.61990076, -0.61771524, -0.6314567 , ...,  0.68108726,\n            0.5785947 , -0.6107257 ]]],\n \n \n        [[[ 0.27674443,  2.4302437 ,  2.2828186 , ...,  0.39748153,\n            0.3145339 ,  0.34234348],\n          [ 0.25582045,  2.3054879 ,  2.1857872 , ...,  2.1514294 ,\n            2.2640743 ,  2.4121022 ],\n          [ 0.23813203,  2.2147424 ,  2.150725  , ...,  2.0948665 ,\n            2.1710038 ,  2.2886076 ],\n          ...,\n          [ 2.9283328 ,  2.7978945 ,  2.7125747 , ...,  2.8352356 ,\n            2.951691  ,  0.67151296],\n          [ 3.1365213 ,  2.9580827 ,  2.8171275 , ...,  2.957601  ,\n            3.1281054 ,  0.5736181 ],\n          [ 0.51572853,  0.4900634 ,  0.46173432, ...,  3.1257463 ,\n            3.3587236 ,  0.61134124]]],\n \n \n        [[[-0.6640173 , -0.79317605,  0.21712588, ..., -0.9345156 ,\n           -0.7889534 , -0.66138905],\n          [-0.7887115 , -0.9538252 ,  0.5867728 , ..., -0.9938241 ,\n           -0.9664194 , -0.79984206],\n          [-0.9300118 , -1.1522644 ,  1.1287699 , ...,  1.7102474 ,\n            0.836242  ,  0.29721054],\n          ...,\n          [-0.6093703 , -0.6842267 , -0.6331321 , ...,  0.7888682 ,\n           -1.0472846 , -0.88644993],\n          [-0.7437675 , -0.9142608 , -1.1131893 , ...,  0.8308829 ,\n           -0.92020607, -0.7442536 ],\n          [-0.61990076, -0.75618756, -0.9047544 , ...,  0.8178514 ,\n           -0.7502721 , -0.6107257 ]]]], dtype=float32),\n 'y_train': array([37, 27, 38, ..., 11, 14, 30]),\n 'x_validation': array([[[[-0.25243405, -0.3884417 , -0.5918168 , ..., -0.4712122 ,\n           -0.2662489 , -0.18904434],\n          [-0.3825046 , -0.54458404, -0.7283045 , ..., -0.68993485,\n           -0.5533882 , -0.38918248],\n          [-0.52116144, -0.7295012 , -1.0269164 , ..., -0.837854  ,\n           -0.6653653 , -0.46984607],\n          ...,\n          [-0.27404296, -0.47838706, -0.77626395, ..., -0.7770479 ,\n            0.06065671,  0.67151296],\n          [-0.12839127, -0.3001446 , -0.5591358 , ..., -0.62151   ,\n            0.52685   ,  1.1978731 ],\n          [ 0.01889069, -0.20229822, -0.3581589 , ..., -0.20787962,\n            1.1381176 ,  1.545863  ]]],\n \n \n        [[[ 1.3204019 ,  0.7679421 ,  0.50603396, ...,  0.6870461 ,\n            0.95339495,  0.5194727 ],\n          [ 2.2143176 ,  1.1362276 , -0.48919955, ...,  2.1514294 ,\n            2.3230789 ,  2.0014427 ],\n          [ 2.5014105 ,  0.946453  ,  0.37827167, ...,  2.287176  ,\n            2.53503   ,  2.5836291 ],\n          ...,\n          [ 2.6600711 ,  1.7000829 ,  1.9969155 , ...,  0.71769005,\n            0.6146273 ,  0.5360379 ],\n          [ 1.7690187 ,  0.99632275,  1.7782773 , ...,  1.0210774 ,\n            1.6810496 ,  1.3365965 ],\n          [ 2.698266  ,  2.6190753 ,  2.4260619 , ...,  1.7581049 ,\n            2.239678  ,  1.9592092 ]]],\n \n \n        [[[ 2.9667346 ,  2.777159  ,  2.6295083 , ...,  2.641607  ,\n            2.7973802 ,  2.9845216 ],\n          [ 2.7946131 ,  2.656266  ,  2.5444446 , ...,  2.5768743 ,\n            2.6771054 ,  2.8227618 ],\n          [ 2.676632  ,  2.5771108 ,  2.533958  , ...,  2.5435886 ,\n            2.595701  ,  2.701638  ],\n          ...,\n          [-0.47523934, -0.6842267 , -0.99096173, ..., -0.4211579 ,\n           -0.70105296, -0.48002478],\n          [-0.4018918 , -0.6413202 , -0.90541923, ..., -0.7598333 ,\n           -0.5067615 , -0.32808354],\n          [-0.33599347, -0.548479  , -0.6997811 , ..., -0.68655413,\n           -0.47051066, -0.17940794]]],\n \n \n        ...,\n \n \n        [[[ 0.6883276 ,  0.42102695,  0.15934427, ..., -0.12373468,\n           -0.0920141 ,  0.04712799],\n          [ 0.37187952,  0.21543512,  0.04878664, ..., -0.5076013 ,\n           -0.14035697, -0.09585425],\n          [ 0.29653922,  0.11602519, -0.13270578, ..., -0.837854  ,\n           -0.54402333, -0.292833  ],\n          ...,\n          [-0.5423049 , -0.27254736,  0.44035667, ...,  1.0557857 ,\n            0.75312   ,  1.6029038 ],\n          [-0.47026694, -0.02720413,  0.6874845 , ...,  2.1276624 ,\n            1.147017  ,  2.2903192 ],\n          [-0.33599347,  0.21311878,  1.0083297 , ...,  1.8948691 ,\n            1.0681771 ,  2.2467544 ]]],\n \n \n        [[[ 2.9667346 ,  2.777159  ,  2.6295083 , ...,  2.641607  ,\n            2.7973802 ,  2.9845216 ],\n          [ 2.7946131 ,  2.656266  ,  2.5444446 , ...,  2.5768743 ,\n            2.6771054 ,  2.8227618 ],\n          [ 2.676632  ,  2.5771108 ,  2.533958  , ...,  2.2230728 ,\n            2.595701  ,  2.701638  ],\n          ...,\n          [ 3.2636602 ,  3.1409605 ,  2.6410089 , ...,  2.5505238 ,\n            1.1512865 ,  0.942463  ],\n          [ 3.478397  ,  3.2992582 ,  3.163411  , ...,  2.957601  ,\n            1.1986976 ,  1.1285114 ],\n          [ 3.7629185 ,  3.5191453 ,  3.3142796 , ...,  2.1000152 ,\n            0.9982368 ,  1.3302041 ]]],\n \n \n        [[[-0.01724364, -0.56189924, -0.18734547, ..., -0.52912515,\n           -0.38240546, -0.07095817],\n          [-0.03432735, -0.6030471 , -0.3696471 , ..., -0.87226844,\n           -0.49438372, -0.0371886 ],\n          [-0.2875327 , -0.7898959 , -0.5798111 , ..., -0.96606034,\n           -0.6046943 , -0.23382866],\n          ...,\n          [-0.27404296, -0.61561346, -0.8478298 , ..., -0.9905819 ,\n           -0.7702994 , -0.6154999 ],\n          [-0.06001614, -0.43661487, -0.4898791 , ..., -0.7598333 ,\n           -0.6445763 , -0.39744523],\n          [ 0.01889069, -0.13306208, -0.28983447, ..., -0.48140788,\n           -0.54045105, -0.32318053]]]], dtype=float32),\n 'labels': ['Speed limit (20km/h)',\n  'Speed limit (30km/h)',\n  'Speed limit (50km/h)',\n  'Speed limit (60km/h)',\n  'Speed limit (70km/h)',\n  'Speed limit (80km/h)',\n  'End of speed limit (80km/h)',\n  'Speed limit (100km/h)',\n  'Speed limit (120km/h)',\n  'No passing',\n  'No passing for vehicles over 3.5 metric tons',\n  'Right-of-way at the next intersection',\n  'Priority road',\n  'Yield',\n  'Stop',\n  'No vehicles',\n  'Vehicles over 3.5 metric tons prohibited',\n  'No entry',\n  'General caution',\n  'Dangerous curve to the left',\n  'Dangerous curve to the right',\n  'Double curve',\n  'Bumpy road',\n  'Slippery road',\n  'Road narrows on the right',\n  'Road work',\n  'Traffic signals',\n  'Pedestrians',\n  'Children crossing',\n  'Bicycles crossing',\n  'Beware of ice/snow',\n  'Wild animals crossing',\n  'End of all speed and passing limits',\n  'Turn right ahead',\n  'Turn left ahead',\n  'Ahead only',\n  'Go straight or right',\n  'Go straight or left',\n  'Keep right',\n  'Keep left',\n  'Roundabout mandatory',\n  'End of no passing',\n  'End of no passing by vehicles over 3.5 metric tons'],\n 'x_test': array([[[[ 5.7073241e-01,  4.2102695e-01,  1.0156265e-01, ...,\n            2.0624781e+00,  2.2746756e+00,  2.4531338e+00],\n          [-3.4327347e-02,  2.1543512e-01,  4.8786644e-02, ...,\n            2.0298736e+00,  2.3230789e+00,  2.4121022e+00],\n          [-4.6275425e-01, -3.0673796e-01, -2.6045015e-01, ...,\n            2.3512793e+00,  2.3530169e+00,  2.2886076e+00],\n          ...,\n          [-3.4110841e-01,  7.5665104e-01,  7.2662032e-01, ...,\n            9.8460770e-01, -7.7835940e-02,  6.1875354e-02],\n          [-1.2839127e-01,  1.1839695e+00,  9.6451133e-01, ...,\n            1.2977237e+00,  1.1340543e-01, -2.5872189e-01],\n          [ 1.8890690e-02,  1.5112969e+00,  1.8843660e-01, ...,\n            1.6213408e+00,  5.0865430e-01,  3.2379606e-01]]],\n \n \n        [[[ 1.4967947e+00,  2.1411479e+00,  2.3406003e+00, ...,\n           -4.7121221e-01, -2.0817064e-01,  4.7127988e-02],\n          [ 1.4019041e+00,  2.1300988e+00,  2.3651159e+00, ...,\n           -2.0371208e-01,  9.5660828e-02,  1.9747403e-01],\n          [ 1.3916740e+00,  2.0939529e+00,  2.2784691e+00, ...,\n            2.5190005e-01,  4.8738366e-01,  8.2824981e-01],\n          ...,\n          [-7.4350125e-01, -8.9006644e-01,  9.2342675e-01, ...,\n           -2.0762385e-01, -5.6256032e-01,  4.0056291e-01],\n          [-4.0189180e-01, -4.3661487e-01,  9.6451133e-01, ...,\n            9.4410853e-04, -3.6894661e-01,  5.0425649e-01],\n          [ 8.9867510e-02,  5.4102424e-03,  1.1962221e+00, ...,\n            2.0241283e-01, -2.6068959e-01,  7.5511384e-01]]],\n \n \n        [[[ 9.2351800e-01,  8.8358045e-01, -4.7625357e-01, ...,\n           -7.6077682e-01, -6.1471856e-01, -5.4330283e-01],\n          [ 6.0399771e-01,  7.4160224e-01, -9.6740949e-01, ...,\n           -9.3304628e-01, -6.7139715e-01, -7.4117637e-01],\n          [ 5.3016794e-01,  6.5957797e-01, -9.6304417e-01, ...,\n           -9.6606034e-01, -8.4737837e-01, -7.6486784e-01],\n          ...,\n          [ 1.2834986e-01, -6.6707648e-02, -6.3313210e-01, ...,\n           -1.2041159e+00, -7.0105296e-01, -3.4454978e-01],\n          [ 2.1348442e-01, -2.7204130e-02, -4.8987910e-01, ...,\n           -8.9815640e-01, -4.3785405e-01, -5.0636895e-02],\n          [-5.2086134e-02, -2.0229822e-01, -2.8983447e-01, ...,\n           -2.7626169e-01, -1.2080890e-01,  3.6250915e-02]]],\n \n \n        ...,\n \n \n        [[[ 1.6143899e+00,  1.4473176e+00,  1.2427497e+00, ...,\n            1.7729133e+00,  1.9842843e+00,  2.0398324e+00],\n          [ 1.5759927e+00,  1.1362276e+00,  1.1098150e+00, ...,\n            1.7259845e+00,  1.7920389e+00,  1.8841114e+00],\n          [ 1.3332669e+00,  9.4645298e-01,  8.7328118e-01, ...,\n            1.3897315e+00,  1.6856359e+00,  1.6395596e+00],\n          ...,\n          [-6.7643577e-01, -7.5283998e-01, -9.9096173e-01, ...,\n           -4.9233589e-01, -2.1632867e-01,  1.9735038e-01],\n          [-5.3864205e-01, -7.0955533e-01, -7.6690590e-01, ...,\n           -6.2151003e-01, -3.6894661e-01,  1.8724766e-02],\n          [-4.0697029e-01, -4.1000673e-01, -5.6313223e-01, ...,\n           -5.4979002e-01, -3.3062994e-01, -1.7940794e-01]]],\n \n \n        [[[-5.4642206e-01, -6.1971843e-01, -2.4512710e-01, ...,\n            2.2374280e-01,  2.5645560e-01,  2.2425729e-01],\n          [-4.9856377e-01, -4.8612106e-01, -7.0765831e-02, ...,\n           -2.1378547e-02, -3.1737038e-01, -3.7188601e-02],\n          [-1.7071831e-01, -7.8989589e-01, -4.5206669e-01, ...,\n           -4.5126667e-03, -4.2268133e-01,  2.3820619e-01],\n          ...,\n          [ 1.0672662e+00,  8.9387745e-01,  4.4035667e-01, ...,\n           -2.0762385e-01,  1.9914937e-01,  6.0377544e-01],\n          [ 1.1707362e+00,  7.9161739e-01,  4.7971445e-01, ...,\n            7.0105672e-02,  3.2012770e-01,  1.5744808e-01],\n          [ 7.9963583e-01,  5.5929959e-01,  1.2011217e-01, ...,\n            4.7594109e-01,  5.7859468e-01,  3.2379606e-01]]],\n \n \n        [[[-4.2882687e-01, -5.0408006e-01, -6.4959848e-01, ...,\n           -6.4495099e-01, -4.4048375e-01, -3.6617362e-01],\n          [-6.1462289e-01, -7.1997315e-01, -9.0763324e-01, ...,\n           -9.3304628e-01, -7.3040158e-01, -6.2384510e-01],\n          [-7.5479025e-01, -9.1068548e-01, -1.2185329e+00, ...,\n           -1.0942668e+00, -8.4737837e-01, -7.0586354e-01],\n          ...,\n          [-6.0937029e-01, -7.5283998e-01, -9.1939574e-01, ...,\n           -9.1940385e-01, -7.0105296e-01, -5.4776239e-01],\n          [-5.3864205e-01, -6.4132023e-01, -7.6690590e-01, ...,\n           -7.5983328e-01, -5.7566893e-01, -3.9744523e-01],\n          [-2.6501665e-01, -4.1000673e-01, -5.6313223e-01, ...,\n           -6.1817205e-01, -4.7051066e-01, -3.2318053e-01]]]],\n       dtype=float32),\n 'y_test': array([25, 11, 38, ...,  8, 33, 10], dtype=uint8)}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(data['x_train']),len(data['y_train']),len(data['x_validation']),len(data['y_validation']),len(data['x_test']),len(data['y_test']))\n","execution_count":4,"outputs":[{"output_type":"stream","text":"86989 86989 4410 4410 12630 12630\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nimport tensorflow as tf\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\n%matplotlib inline","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize image vectors\nX_train = data['x_train']/255.\nX_test = data['x_test']/255.\nX_validation = data['x_validation']/.255\n\n# Reshape\nY_train = data['y_train'].T\nY_test = data['y_test'].T\nY_validation = data['y_validation'].T\n\nprint (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of Validation examples = \" + str(X_validation.shape[0]))\nprint (\"number of test examples = \" + str(X_test.shape[0]))\n\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\n\nprint (\"X_validation shape: \" + str(X_validation.shape))\nprint (\"Y_validation shape: \" + str(Y_validation.shape))\n\nprint (\"X_test shape: \" + str(X_test.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))\n","execution_count":6,"outputs":[{"output_type":"stream","text":"number of training examples = 86989\nnumber of Validation examples = 4410\nnumber of test examples = 12630\nX_train shape: (86989, 1, 32, 32)\nY_train shape: (86989,)\nX_validation shape: (4410, 1, 32, 32)\nY_validation shape: (4410,)\nX_test shape: (12630, 1, 32, 32)\nY_test shape: (12630,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_validation = X_validation.transpose(0, 2, 3, 1)\nx_train = X_train.transpose(0, 2, 3, 1)\nx_test = X_test.transpose(0, 2, 3, 1)\nprint(x_train.shape,x_validation.shape,x_test.shape)","execution_count":7,"outputs":[{"output_type":"stream","text":"(86989, 32, 32, 1) (4410, 32, 32, 1) (12630, 32, 32, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(input_shape):\n\n    X_input = Input(input_shape)\n\n    # Zero-Padding: pads the border of X_input with zeroes\n    X = ZeroPadding2D((3, 3))(X_input)\n\n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(16, (3, 3), strides = (1, 1), name = 'conv0')(X)\n    print(X)\n    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D((2, 2), name='max_pool0')(X)\n    \n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv1')(X)\n    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n    \n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv2')(X)\n    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D((2, 2), name='max_pool2')(X)\n    \n\n    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n    X = Flatten()(X)\n    X = Dense(1, activation='sigmoid', name='fc')(X)\n\n    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n    model = Model(inputs = X_input, outputs = X)\n\n    \n    \n    return model","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model = model(x_train.shape[1:])","execution_count":9,"outputs":[{"output_type":"stream","text":"Tensor(\"conv0/Identity:0\", shape=(None, 36, 36, 16), dtype=float32)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model.compile(optimizer='Adadelta', loss = 'binary_crossentropy', metrics = [\"accuracy\"])","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model.fit(x = x_train , y = Y_train, epochs = 50, batch_size = 1000)","execution_count":11,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n87/87 [==============================] - 2s 19ms/step - loss: 5.0870 - accuracy: 0.0250\nEpoch 2/50\n87/87 [==============================] - 2s 18ms/step - loss: 1.6402 - accuracy: 0.0251\nEpoch 3/50\n87/87 [==============================] - 2s 18ms/step - loss: -2.0463 - accuracy: 0.0253\nEpoch 4/50\n87/87 [==============================] - 2s 18ms/step - loss: -5.9466 - accuracy: 0.0252\nEpoch 5/50\n87/87 [==============================] - 2s 18ms/step - loss: -10.0451 - accuracy: 0.0251\nEpoch 6/50\n87/87 [==============================] - 2s 18ms/step - loss: -14.3404 - accuracy: 0.0243\nEpoch 7/50\n87/87 [==============================] - 2s 18ms/step - loss: -18.8122 - accuracy: 0.0238\nEpoch 8/50\n87/87 [==============================] - 2s 18ms/step - loss: -23.4524 - accuracy: 0.0236\nEpoch 9/50\n87/87 [==============================] - 2s 18ms/step - loss: -28.2509 - accuracy: 0.0235\nEpoch 10/50\n87/87 [==============================] - 2s 18ms/step - loss: -33.2076 - accuracy: 0.0233\nEpoch 11/50\n87/87 [==============================] - 2s 18ms/step - loss: -38.2847 - accuracy: 0.0232\nEpoch 12/50\n87/87 [==============================] - 2s 18ms/step - loss: -43.4738 - accuracy: 0.0231\nEpoch 13/50\n87/87 [==============================] - 2s 18ms/step - loss: -48.7667 - accuracy: 0.0230\nEpoch 14/50\n87/87 [==============================] - 2s 18ms/step - loss: -54.1352 - accuracy: 0.0230\nEpoch 15/50\n87/87 [==============================] - 2s 20ms/step - loss: -59.5763 - accuracy: 0.0231\nEpoch 16/50\n87/87 [==============================] - 2s 19ms/step - loss: -65.0901 - accuracy: 0.0231\nEpoch 17/50\n87/87 [==============================] - 2s 18ms/step - loss: -70.6707 - accuracy: 0.0231\nEpoch 18/50\n87/87 [==============================] - 2s 18ms/step - loss: -76.3304 - accuracy: 0.0232\nEpoch 19/50\n87/87 [==============================] - 2s 18ms/step - loss: -82.0239 - accuracy: 0.0232\nEpoch 20/50\n87/87 [==============================] - 2s 18ms/step - loss: -87.7487 - accuracy: 0.0232\nEpoch 21/50\n87/87 [==============================] - 2s 18ms/step - loss: -93.5243 - accuracy: 0.0232\nEpoch 22/50\n87/87 [==============================] - 2s 18ms/step - loss: -99.3541 - accuracy: 0.0232\nEpoch 23/50\n87/87 [==============================] - 2s 18ms/step - loss: -105.2494 - accuracy: 0.0233\nEpoch 24/50\n87/87 [==============================] - 2s 18ms/step - loss: -111.2345 - accuracy: 0.0233\nEpoch 25/50\n87/87 [==============================] - 2s 17ms/step - loss: -117.3103 - accuracy: 0.0233\nEpoch 26/50\n87/87 [==============================] - 2s 18ms/step - loss: -123.4816 - accuracy: 0.0233\nEpoch 27/50\n87/87 [==============================] - 2s 17ms/step - loss: -129.7601 - accuracy: 0.0233\nEpoch 28/50\n87/87 [==============================] - 2s 18ms/step - loss: -136.1492 - accuracy: 0.0233\nEpoch 29/50\n87/87 [==============================] - 2s 18ms/step - loss: -142.6756 - accuracy: 0.0233\nEpoch 30/50\n87/87 [==============================] - 2s 18ms/step - loss: -149.3382 - accuracy: 0.0233\nEpoch 31/50\n87/87 [==============================] - 2s 18ms/step - loss: -156.1306 - accuracy: 0.0233\nEpoch 32/50\n87/87 [==============================] - 2s 18ms/step - loss: -163.0775 - accuracy: 0.0233\nEpoch 33/50\n87/87 [==============================] - 2s 18ms/step - loss: -170.1902 - accuracy: 0.0233\nEpoch 34/50\n87/87 [==============================] - 2s 18ms/step - loss: -177.4737 - accuracy: 0.0233\nEpoch 35/50\n87/87 [==============================] - 2s 18ms/step - loss: -184.8964 - accuracy: 0.0233\nEpoch 36/50\n87/87 [==============================] - 2s 18ms/step - loss: -192.5329 - accuracy: 0.0233\nEpoch 37/50\n87/87 [==============================] - 2s 18ms/step - loss: -200.3371 - accuracy: 0.0233\nEpoch 38/50\n87/87 [==============================] - 2s 18ms/step - loss: -208.3166 - accuracy: 0.0233\nEpoch 39/50\n87/87 [==============================] - 2s 17ms/step - loss: -216.4965 - accuracy: 0.0233\nEpoch 40/50\n87/87 [==============================] - 2s 17ms/step - loss: -224.8376 - accuracy: 0.0233\nEpoch 41/50\n87/87 [==============================] - 2s 18ms/step - loss: -233.3527 - accuracy: 0.0233\nEpoch 42/50\n87/87 [==============================] - 2s 17ms/step - loss: -242.0567 - accuracy: 0.0233\nEpoch 43/50\n87/87 [==============================] - 2s 17ms/step - loss: -250.9347 - accuracy: 0.0233\nEpoch 44/50\n87/87 [==============================] - 2s 18ms/step - loss: -260.0104 - accuracy: 0.0233\nEpoch 45/50\n87/87 [==============================] - 2s 18ms/step - loss: -269.2675 - accuracy: 0.0233\nEpoch 46/50\n87/87 [==============================] - 2s 18ms/step - loss: -278.6223 - accuracy: 0.0233\nEpoch 47/50\n87/87 [==============================] - 2s 18ms/step - loss: -288.0806 - accuracy: 0.0233\nEpoch 48/50\n87/87 [==============================] - 2s 18ms/step - loss: -297.6260 - accuracy: 0.0233\nEpoch 49/50\n87/87 [==============================] - 2s 17ms/step - loss: -307.2206 - accuracy: 0.0233\nEpoch 50/50\n87/87 [==============================] - 2s 17ms/step - loss: -316.8961 - accuracy: 0.0233\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f715ed12ad0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = Model.evaluate(x = x_validation, y = Y_validation )\nprint()\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","execution_count":12,"outputs":[{"output_type":"stream","text":"138/138 [==============================] - 0s 2ms/step - loss: -193977.4531 - accuracy: 0.0544\n\nLoss = -193977.453125\nTest Accuracy = 0.054421767592430115\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = Model.evaluate(x = x_test, y = Y_test)\nprint()\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","execution_count":13,"outputs":[{"output_type":"stream","text":"395/395 [==============================] - 1s 3ms/step - loss: -236.2888 - accuracy: 0.0570\n\nLoss = -236.288818359375\nTest Accuracy = 0.05700712651014328\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}